{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import imageio\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"hockey_fight_videos\"\n",
    "BATCH_SIZE = 64\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (36, 28, 28, 3)\n",
    "NUM_CLASSES = 2\n",
    "LABELS = [\"no\",\"fi\"]\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0.00001\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 100\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (8, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# veri kümenizi yükleyin\n",
    "data_path = \"C:/Users/Emirhan/Downloads/data\"\n",
    "classes = os.listdir(data_path)\n",
    "\n",
    "videos = []\n",
    "labels = []\n",
    "train_files = []\n",
    "val_files = []\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(data_path, cls)\n",
    "    files = os.listdir(cls_path)\n",
    "    for video in os.listdir(cls_path):\n",
    "        video_path = os.path.join(cls_path, video)\n",
    "        videos.append(video_path)\n",
    "        label = os.path.basename(video_path).split('_')[0][0:2]\n",
    "        if label not in LABELS:\n",
    "            continue\n",
    "        labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "videos = np.array(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emirhan\\anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Örnek veri etiketleri\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels = encoder.fit_transform(np.array(labels).reshape(-1, 1))\n",
    "\n",
    "# Kodlanmış etiketleri kontrol etme\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 36, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Videoların yollarını içeren bir liste oluşturma\n",
    "video_paths = videos\n",
    "\n",
    "# En kısa video uzunluğunu belirleme\n",
    "min_frame_count = float('inf')\n",
    "\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count < min_frame_count:\n",
    "        min_frame_count = frame_count\n",
    "\n",
    "# Tüm videolardan aynı sayıda frame almak için döngü\n",
    "frames = []\n",
    "\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    selected_frames = []\n",
    "    for i in range(min_frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (28,28))\n",
    "            selected_frames.append(frame)\n",
    "    frames.append(np.array(selected_frames))\n",
    "\n",
    "# Tüm videolardaki ortak frame sayısına sahip bir matris oluşturma\n",
    "video_array = np.stack(frames)\n",
    "\n",
    "# Video dizisinin şeklini yazdırma\n",
    "print(video_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(video_array, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = \"train\",\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "trainloader = prepare_dataloader(X_train, y_train, \"train\")\n",
    "validloader = prepare_dataloader(X_val, y_val, \"valid\")\n",
    "testloader = prepare_dataloader(X_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 36, 28, 28, 3, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUBELET EMBEDDING\n",
    "\n",
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIONAL \n",
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 14s 136ms/step - loss: 0.7844 - accuracy: 0.4837 - val_loss: 0.7503 - val_accuracy: 0.4933\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.6862 - accuracy: 0.5630 - val_loss: 0.7927 - val_accuracy: 0.4933\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6879 - accuracy: 0.5526 - val_loss: 0.7714 - val_accuracy: 0.4933\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.6665 - accuracy: 0.6059 - val_loss: 0.9102 - val_accuracy: 0.4933\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.6334 - accuracy: 0.6407 - val_loss: 1.2121 - val_accuracy: 0.4933\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.6023 - accuracy: 0.6519 - val_loss: 1.3483 - val_accuracy: 0.4933\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.6349 - accuracy: 0.6356 - val_loss: 1.4950 - val_accuracy: 0.4933\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5771 - accuracy: 0.6689 - val_loss: 1.4857 - val_accuracy: 0.4933\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5603 - accuracy: 0.6874 - val_loss: 1.8121 - val_accuracy: 0.4933\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5669 - accuracy: 0.6822 - val_loss: 1.7259 - val_accuracy: 0.4933\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5194 - accuracy: 0.7215 - val_loss: 1.5469 - val_accuracy: 0.4933\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.5075 - accuracy: 0.7341 - val_loss: 1.4465 - val_accuracy: 0.4933\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5621 - accuracy: 0.6978 - val_loss: 1.3050 - val_accuracy: 0.4933\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5337 - accuracy: 0.7170 - val_loss: 1.2586 - val_accuracy: 0.4933\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.4900 - accuracy: 0.7526 - val_loss: 1.4129 - val_accuracy: 0.4933\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4737 - accuracy: 0.7444 - val_loss: 1.6616 - val_accuracy: 0.4933\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.4921 - accuracy: 0.7178 - val_loss: 1.4512 - val_accuracy: 0.4933\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4732 - accuracy: 0.7519 - val_loss: 1.4281 - val_accuracy: 0.4933\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4301 - accuracy: 0.7726 - val_loss: 1.4196 - val_accuracy: 0.4933\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.4048 - accuracy: 0.7919 - val_loss: 1.3200 - val_accuracy: 0.4933\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4152 - accuracy: 0.7881 - val_loss: 1.2581 - val_accuracy: 0.4933\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3886 - accuracy: 0.7985 - val_loss: 1.1522 - val_accuracy: 0.4933\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4109 - accuracy: 0.7763 - val_loss: 0.8171 - val_accuracy: 0.4933\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3775 - accuracy: 0.8089 - val_loss: 1.0282 - val_accuracy: 0.4933\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.4042 - accuracy: 0.7859 - val_loss: 1.2110 - val_accuracy: 0.4933\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3685 - accuracy: 0.8170 - val_loss: 1.5704 - val_accuracy: 0.4933\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3458 - accuracy: 0.8207 - val_loss: 1.7700 - val_accuracy: 0.4933\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3782 - accuracy: 0.7970 - val_loss: 1.2677 - val_accuracy: 0.4933\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.3327 - accuracy: 0.8274 - val_loss: 1.6059 - val_accuracy: 0.4933\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.3187 - accuracy: 0.8348 - val_loss: 1.8801 - val_accuracy: 0.4933\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.3819 - accuracy: 0.8074 - val_loss: 1.1619 - val_accuracy: 0.4933\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.3323 - accuracy: 0.8422 - val_loss: 1.8352 - val_accuracy: 0.4933\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.3297 - accuracy: 0.8385 - val_loss: 2.2868 - val_accuracy: 0.4933\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3056 - accuracy: 0.8541 - val_loss: 2.8520 - val_accuracy: 0.4933\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3028 - accuracy: 0.8556 - val_loss: 2.0232 - val_accuracy: 0.4933\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2981 - accuracy: 0.8548 - val_loss: 2.6399 - val_accuracy: 0.4933\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2796 - accuracy: 0.8563 - val_loss: 2.8501 - val_accuracy: 0.4933\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3177 - accuracy: 0.8519 - val_loss: 2.3063 - val_accuracy: 0.4933\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2582 - accuracy: 0.8726 - val_loss: 3.1184 - val_accuracy: 0.4933\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.2447 - accuracy: 0.8859 - val_loss: 3.4895 - val_accuracy: 0.4933\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2509 - accuracy: 0.8837 - val_loss: 3.4036 - val_accuracy: 0.4933\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 3.2207 - val_accuracy: 0.4933\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2231 - accuracy: 0.8941 - val_loss: 3.6221 - val_accuracy: 0.4933\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2250 - accuracy: 0.8859 - val_loss: 4.0345 - val_accuracy: 0.4933\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2115 - accuracy: 0.9052 - val_loss: 3.8624 - val_accuracy: 0.4933\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2252 - accuracy: 0.8867 - val_loss: 3.9740 - val_accuracy: 0.4933\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1937 - accuracy: 0.9104 - val_loss: 4.2707 - val_accuracy: 0.4933\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 3.8438 - val_accuracy: 0.4933\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2014 - accuracy: 0.9007 - val_loss: 3.5393 - val_accuracy: 0.4933\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.1782 - accuracy: 0.9141 - val_loss: 4.3945 - val_accuracy: 0.4933\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1728 - accuracy: 0.9281 - val_loss: 4.5697 - val_accuracy: 0.4933\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1517 - accuracy: 0.9356 - val_loss: 4.6611 - val_accuracy: 0.4933\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1491 - accuracy: 0.9356 - val_loss: 4.5276 - val_accuracy: 0.4933\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1673 - accuracy: 0.9274 - val_loss: 4.3650 - val_accuracy: 0.4933\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2018 - accuracy: 0.9119 - val_loss: 4.4855 - val_accuracy: 0.4933\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1379 - accuracy: 0.9385 - val_loss: 4.6271 - val_accuracy: 0.4933\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1407 - accuracy: 0.9415 - val_loss: 4.7262 - val_accuracy: 0.4933\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.3248 - accuracy: 0.8830 - val_loss: 4.0225 - val_accuracy: 0.4933\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.1669 - accuracy: 0.9281 - val_loss: 4.2164 - val_accuracy: 0.4933\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.1137 - accuracy: 0.9519 - val_loss: 4.3025 - val_accuracy: 0.4933\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.1086 - accuracy: 0.9556 - val_loss: 4.5386 - val_accuracy: 0.4933\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0969 - accuracy: 0.9659 - val_loss: 4.6545 - val_accuracy: 0.4933\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0764 - accuracy: 0.9711 - val_loss: 4.8095 - val_accuracy: 0.4933\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1892 - accuracy: 0.9193 - val_loss: 4.4893 - val_accuracy: 0.4933\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.1248 - accuracy: 0.9548 - val_loss: 4.6755 - val_accuracy: 0.4933\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0686 - accuracy: 0.9741 - val_loss: 4.8485 - val_accuracy: 0.4933\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 4.9212 - val_accuracy: 0.4933\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 5.0243 - val_accuracy: 0.4933\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 5.0519 - val_accuracy: 0.4933\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 5.1414 - val_accuracy: 0.4933\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.0919 - accuracy: 0.9652 - val_loss: 5.0820 - val_accuracy: 0.4933\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.0979 - accuracy: 0.9667 - val_loss: 5.0350 - val_accuracy: 0.4933\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.1340 - accuracy: 0.9511 - val_loss: 4.6146 - val_accuracy: 0.4933\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 4.8573 - val_accuracy: 0.4933\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0461 - accuracy: 0.9830 - val_loss: 4.9343 - val_accuracy: 0.4933\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 5.0514 - val_accuracy: 0.4933\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 5.1142 - val_accuracy: 0.4933\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 5.1362 - val_accuracy: 0.4933\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 5.1693 - val_accuracy: 0.4933\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 5.1852 - val_accuracy: 0.4933\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 5.2263 - val_accuracy: 0.4933\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0148 - accuracy: 0.9933 - val_loss: 5.2285 - val_accuracy: 0.4933\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 5.2375 - val_accuracy: 0.4933\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 5.2495 - val_accuracy: 0.4933\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 5.1196 - val_accuracy: 0.4933\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 5.0598 - val_accuracy: 0.4933\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 5.1177 - val_accuracy: 0.4933\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 5.1768 - val_accuracy: 0.4933\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 5.2060 - val_accuracy: 0.4933\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 5.2271 - val_accuracy: 0.4933\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 5.2391 - val_accuracy: 0.4933\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 5.2056 - val_accuracy: 0.4933\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.4172 - accuracy: 0.8356 - val_loss: 4.3295 - val_accuracy: 0.4933\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2925 - accuracy: 0.8607 - val_loss: 3.8886 - val_accuracy: 0.4933\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2352 - accuracy: 0.8926 - val_loss: 4.2605 - val_accuracy: 0.4933\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.1569 - accuracy: 0.9370 - val_loss: 4.5267 - val_accuracy: 0.4933\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.1128 - accuracy: 0.9563 - val_loss: 4.6903 - val_accuracy: 0.4933\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0612 - accuracy: 0.9807 - val_loss: 4.9187 - val_accuracy: 0.4933\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0805 - accuracy: 0.9674 - val_loss: 4.8301 - val_accuracy: 0.4933\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.1060 - accuracy: 0.9578 - val_loss: 4.9949 - val_accuracy: 0.4933\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    # Initialize model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy'\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 36, 28, 28,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " tubelet_embedding (TubeletEmbe  (None, 36, 128)     196736      ['input_1[0][0]']                \n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " positional_encoder (Positional  (None, 36, 128)     4608        ['tubelet_embedding[0][0]']      \n",
      " Encoder)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 36, 128)     256         ['positional_encoder[0][0]']     \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 36, 128)     66048       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 36, 128)      0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'positional_encoder[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 36, 128)     256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 36, 128)      131712      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 36, 128)      0           ['sequential[0][0]',             \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 36, 128)     256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 36, 128)     66048       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 36, 128)      0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 36, 128)     256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 36, 128)      0           ['sequential_1[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 36, 128)     256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 36, 128)     66048       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 36, 128)      0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 36, 128)     256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 36, 128)      0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 36, 128)     256         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 36, 128)     66048       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 36, 128)      0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 36, 128)     256         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 36, 128)      0           ['sequential_3[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 36, 128)     256         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 36, 128)     66048       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 36, 128)      0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 36, 128)     256         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 36, 128)      0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 36, 128)     256         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 36, 128)     66048       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 36, 128)      0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 36, 128)     256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 36, 128)      0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 36, 128)     256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 36, 128)     66048       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 36, 128)      0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 36, 128)     256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 36, 128)      0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 36, 128)     256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 36, 128)     66048       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 36, 128)      0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 36, 128)     256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 36, 128)      0           ['sequential_7[0][0]',           \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 36, 128)     256         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_16[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 2)            258         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,788,034\n",
      "Trainable params: 1,788,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 23ms/step\n",
      "[[1.00000000e+00 3.09020791e-08]\n",
      " [1.17269182e-03 9.98827279e-01]\n",
      " [8.01960632e-05 9.99919772e-01]\n",
      " [9.99992847e-01 7.14621319e-06]\n",
      " [2.34825988e-04 9.99765217e-01]\n",
      " [9.99265730e-01 7.34223227e-04]\n",
      " [1.00000000e+00 1.88673788e-08]\n",
      " [1.42474956e-08 1.00000000e+00]\n",
      " [3.90096358e-03 9.96098995e-01]\n",
      " [1.44327732e-08 1.00000000e+00]\n",
      " [9.99989390e-01 1.06207917e-05]\n",
      " [1.76939974e-08 1.00000000e+00]\n",
      " [1.79377399e-04 9.99820650e-01]\n",
      " [8.89930248e-01 1.10069707e-01]\n",
      " [2.57459465e-06 9.99997377e-01]\n",
      " [6.74042226e-08 9.99999881e-01]\n",
      " [1.00000000e+00 1.61870783e-08]\n",
      " [9.20372367e-01 7.96276107e-02]\n",
      " [1.89963691e-02 9.81003642e-01]\n",
      " [9.59989488e-01 4.00104932e-02]\n",
      " [5.75215563e-05 9.99942422e-01]\n",
      " [1.33834615e-01 8.66165340e-01]\n",
      " [1.68547700e-08 1.00000000e+00]\n",
      " [3.60223638e-08 1.00000000e+00]\n",
      " [9.99988675e-01 1.13258393e-05]\n",
      " [8.65144187e-08 9.99999881e-01]\n",
      " [1.90496841e-03 9.98094976e-01]\n",
      " [2.20354614e-05 9.99977946e-01]\n",
      " [4.36792493e-01 5.63207507e-01]\n",
      " [6.75518112e-03 9.93244827e-01]\n",
      " [5.43897440e-05 9.99945641e-01]\n",
      " [9.99977589e-01 2.24303276e-05]\n",
      " [9.46323097e-01 5.36769293e-02]\n",
      " [6.36543573e-09 1.00000000e+00]\n",
      " [3.97250597e-06 9.99996066e-01]\n",
      " [4.13152911e-02 9.58684683e-01]\n",
      " [5.91508353e-07 9.99999404e-01]\n",
      " [9.99529600e-01 4.70380532e-04]\n",
      " [4.14205641e-01 5.85794330e-01]\n",
      " [9.99995112e-01 4.85049259e-06]\n",
      " [9.34063435e-01 6.59365803e-02]\n",
      " [9.99346435e-01 6.53587573e-04]\n",
      " [7.10686379e-07 9.99999285e-01]\n",
      " [2.83548713e-01 7.16451287e-01]\n",
      " [2.84162507e-08 1.00000000e+00]\n",
      " [9.65835625e-07 9.99999046e-01]\n",
      " [9.81509515e-07 9.99999046e-01]\n",
      " [3.02771777e-02 9.69722867e-01]\n",
      " [9.99997020e-01 3.01105320e-06]\n",
      " [1.00000000e+00 4.43876083e-08]\n",
      " [9.99999166e-01 8.33501815e-07]\n",
      " [1.06865645e-08 1.00000000e+00]\n",
      " [1.22866849e-03 9.98771369e-01]\n",
      " [9.97010112e-01 2.98986514e-03]\n",
      " [9.99999881e-01 1.06249864e-07]\n",
      " [1.27255660e-07 9.99999881e-01]\n",
      " [9.99993563e-01 6.38246138e-06]\n",
      " [9.99717176e-01 2.82786350e-04]\n",
      " [1.15587543e-04 9.99884367e-01]\n",
      " [8.01164564e-03 9.91988420e-01]\n",
      " [2.74187714e-05 9.99972582e-01]\n",
      " [2.35126056e-02 9.76487398e-01]\n",
      " [8.61310923e-07 9.99999166e-01]\n",
      " [4.57840588e-06 9.99995470e-01]\n",
      " [7.55757391e-01 2.44242549e-01]\n",
      " [8.44197334e-09 1.00000000e+00]\n",
      " [1.02880930e-08 1.00000000e+00]\n",
      " [9.99999642e-01 3.09805756e-07]\n",
      " [9.99998569e-01 1.41732380e-06]\n",
      " [3.99507769e-07 9.99999642e-01]\n",
      " [2.63344262e-08 1.00000000e+00]\n",
      " [9.99999881e-01 1.45624099e-07]\n",
      " [1.00000000e+00 1.09315614e-08]\n",
      " [3.18968305e-05 9.99968052e-01]\n",
      " [9.65341806e-01 3.46582420e-02]\n",
      " [4.43326122e-08 1.00000000e+00]\n",
      " [9.98800516e-01 1.19947467e-03]\n",
      " [6.20089047e-09 1.00000000e+00]\n",
      " [2.29040393e-06 9.99997735e-01]\n",
      " [1.52585322e-08 1.00000000e+00]\n",
      " [9.99996185e-01 3.83044926e-06]\n",
      " [9.99381542e-01 6.18462625e-04]\n",
      " [5.40182210e-09 1.00000000e+00]\n",
      " [1.22138730e-03 9.98778641e-01]\n",
      " [2.18176610e-05 9.99978185e-01]\n",
      " [9.99999642e-01 3.01479162e-07]\n",
      " [1.00000000e+00 4.16620294e-09]\n",
      " [5.68953156e-03 9.94310498e-01]\n",
      " [9.99999881e-01 1.50001597e-07]\n",
      " [9.28195252e-04 9.99071836e-01]\n",
      " [1.00000000e+00 5.03462916e-09]\n",
      " [9.84581530e-01 1.54184997e-02]\n",
      " [9.99870777e-01 1.29259555e-04]\n",
      " [1.64472604e-05 9.99983549e-01]\n",
      " [9.99898314e-01 1.01673162e-04]\n",
      " [4.88549676e-06 9.99995112e-01]\n",
      " [3.71532440e-02 9.62846756e-01]\n",
      " [1.26016522e-08 1.00000000e+00]\n",
      " [9.99998331e-01 1.63597986e-06]\n",
      " [2.37397812e-02 9.76260245e-01]\n",
      " [1.00000000e+00 3.80300804e-08]\n",
      " [9.99722779e-01 2.77167856e-04]\n",
      " [9.99999523e-01 5.09312372e-07]\n",
      " [9.84382689e-01 1.56173613e-02]\n",
      " [3.18264775e-02 9.68173563e-01]\n",
      " [9.99999642e-01 4.04376664e-07]\n",
      " [9.99999523e-01 4.55634705e-07]\n",
      " [1.58560351e-02 9.84143972e-01]\n",
      " [9.62170422e-01 3.78295146e-02]\n",
      " [1.00000000e+00 3.19574163e-08]\n",
      " [6.02635382e-08 9.99999881e-01]\n",
      " [9.67556238e-03 9.90324497e-01]\n",
      " [9.99999404e-01 5.52881772e-07]\n",
      " [5.85472947e-07 9.99999404e-01]\n",
      " [1.30712408e-06 9.99998689e-01]\n",
      " [1.00000000e+00 4.00352924e-08]\n",
      " [9.99179184e-01 8.20838613e-04]\n",
      " [2.63029012e-08 1.00000000e+00]\n",
      " [9.98986304e-01 1.01366430e-03]\n",
      " [1.47839737e-05 9.99985218e-01]\n",
      " [2.42669867e-05 9.99975681e-01]\n",
      " [6.70526248e-08 9.99999881e-01]\n",
      " [9.96385455e-01 3.61449295e-03]\n",
      " [1.11316778e-01 8.88683200e-01]\n",
      " [9.07617097e-04 9.99092340e-01]\n",
      " [1.13866721e-04 9.99886155e-01]\n",
      " [9.99998927e-01 1.11577276e-06]\n",
      " [1.78347298e-04 9.99821723e-01]\n",
      " [1.59146758e-08 1.00000000e+00]\n",
      " [9.99987006e-01 1.30474318e-05]\n",
      " [9.99999881e-01 8.42301375e-08]\n",
      " [4.69227359e-02 9.53077316e-01]\n",
      " [9.98843789e-01 1.15616398e-03]\n",
      " [7.61507952e-04 9.99238491e-01]\n",
      " [1.00000000e+00 2.89931723e-09]\n",
      " [1.01812801e-03 9.98981893e-01]\n",
      " [1.05423785e-08 1.00000000e+00]\n",
      " [9.99813020e-01 1.87061669e-04]\n",
      " [1.43993483e-03 9.98560131e-01]\n",
      " [2.15622317e-03 9.97843742e-01]\n",
      " [9.99999285e-01 6.61272395e-07]\n",
      " [9.99999881e-01 1.24325467e-07]\n",
      " [1.30988980e-08 1.00000000e+00]\n",
      " [4.62150946e-03 9.95378494e-01]\n",
      " [9.99999881e-01 8.85434090e-08]\n",
      " [9.99999881e-01 1.48510438e-07]\n",
      " [9.99725878e-01 2.74119433e-04]\n",
      " [4.38163610e-04 9.99561846e-01]\n",
      " [2.59630148e-08 1.00000000e+00]\n",
      " [1.01455084e-08 1.00000000e+00]\n",
      " [9.99431789e-01 5.68203453e-04]\n",
      " [2.03195680e-03 9.97968018e-01]\n",
      " [9.99981880e-01 1.81535906e-05]\n",
      " [8.82582426e-01 1.17417581e-01]\n",
      " [1.00000000e+00 3.35435715e-08]\n",
      " [9.99440253e-01 5.59737848e-04]\n",
      " [2.78345644e-01 7.21654296e-01]\n",
      " [9.99786437e-01 2.13591629e-04]\n",
      " [9.99998927e-01 1.08410939e-06]\n",
      " [6.90883398e-01 3.09116602e-01]\n",
      " [9.99719679e-01 2.80308275e-04]\n",
      " [9.89662290e-01 1.03377141e-02]\n",
      " [6.54996654e-07 9.99999404e-01]\n",
      " [2.65599538e-05 9.99973416e-01]\n",
      " [2.39939777e-06 9.99997616e-01]\n",
      " [9.99999762e-01 1.79681521e-07]\n",
      " [3.26239446e-04 9.99673724e-01]\n",
      " [9.00548577e-01 9.94514152e-02]\n",
      " [8.48481715e-01 1.51518285e-01]\n",
      " [9.99999285e-01 6.87445322e-07]\n",
      " [3.27030284e-06 9.99996781e-01]\n",
      " [5.81691779e-07 9.99999404e-01]\n",
      " [9.99984264e-01 1.57600025e-05]\n",
      " [9.99991894e-01 8.13475708e-06]\n",
      " [9.99999881e-01 9.80134800e-08]\n",
      " [4.07351223e-07 9.99999642e-01]\n",
      " [6.73484291e-09 1.00000000e+00]\n",
      " [9.99999642e-01 3.98774631e-07]\n",
      " [8.40303164e-06 9.99991655e-01]\n",
      " [1.46080552e-08 1.00000000e+00]\n",
      " [2.15592863e-05 9.99978423e-01]\n",
      " [9.94379342e-01 5.62062766e-03]\n",
      " [9.98571515e-01 1.42848107e-03]\n",
      " [1.38316464e-04 9.99861717e-01]\n",
      " [9.99999642e-01 3.13885437e-07]\n",
      " [5.29231548e-01 4.70768452e-01]\n",
      " [9.99782264e-01 2.17755471e-04]\n",
      " [7.28060119e-03 9.92719412e-01]\n",
      " [1.60487446e-07 9.99999881e-01]\n",
      " [3.43187293e-03 9.96568084e-01]\n",
      " [9.99999046e-01 9.77414516e-07]\n",
      " [9.99991655e-01 8.37740299e-06]\n",
      " [1.00000000e+00 2.11303810e-08]\n",
      " [8.40165448e-09 1.00000000e+00]\n",
      " [1.65567577e-08 1.00000000e+00]\n",
      " [2.09483190e-07 9.99999762e-01]\n",
      " [9.96140897e-01 3.85908294e-03]\n",
      " [9.99999881e-01 8.37171257e-08]\n",
      " [4.32188535e-05 9.99956727e-01]\n",
      " [1.30476314e-08 1.00000000e+00]\n",
      " [1.03650630e-01 8.96349311e-01]\n",
      " [7.74873607e-03 9.92251217e-01]\n",
      " [7.93804884e-01 2.06195042e-01]\n",
      " [9.73772287e-01 2.62277275e-02]\n",
      " [2.33570162e-07 9.99999762e-01]\n",
      " [2.29017180e-03 9.97709870e-01]\n",
      " [9.99999404e-01 6.48275716e-07]\n",
      " [9.99081254e-01 9.18744947e-04]\n",
      " [3.12720775e-04 9.99687314e-01]\n",
      " [1.25079271e-08 1.00000000e+00]\n",
      " [1.48525491e-01 8.51474524e-01]\n",
      " [9.99986053e-01 1.39385584e-05]\n",
      " [1.32679787e-07 9.99999881e-01]\n",
      " [4.33787564e-03 9.95662153e-01]\n",
      " [9.99998927e-01 1.01430317e-06]\n",
      " [6.09069943e-01 3.90930027e-01]\n",
      " [9.99999285e-01 7.46167871e-07]\n",
      " [5.49358228e-05 9.99945045e-01]\n",
      " [1.00000000e+00 4.68665675e-08]\n",
      " [3.94837074e-02 9.60516334e-01]\n",
      " [9.99750674e-01 2.49335892e-04]\n",
      " [4.73746953e-09 1.00000000e+00]\n",
      " [9.98506844e-01 1.49316294e-03]\n",
      " [7.85334109e-09 1.00000000e+00]\n",
      " [1.44390156e-03 9.98556077e-01]\n",
      " [1.26426698e-07 9.99999881e-01]\n",
      " [3.10894902e-05 9.99968886e-01]\n",
      " [9.75679457e-01 2.43205838e-02]\n",
      " [9.99998212e-01 1.81780285e-06]\n",
      " [9.99901652e-01 9.82847050e-05]\n",
      " [2.12967972e-08 1.00000000e+00]\n",
      " [1.95458412e-01 8.04541647e-01]\n",
      " [2.56866100e-04 9.99743164e-01]\n",
      " [8.89754290e-07 9.99999166e-01]\n",
      " [1.36176550e-06 9.99998689e-01]\n",
      " [4.99708186e-08 1.00000000e+00]\n",
      " [2.92479277e-01 7.07520664e-01]\n",
      " [1.00000000e+00 3.06088914e-08]\n",
      " [3.66804861e-02 9.63319480e-01]\n",
      " [1.00000000e+00 4.55433131e-08]\n",
      " [2.45009810e-01 7.54990220e-01]\n",
      " [9.99999523e-01 4.42825865e-07]\n",
      " [1.00000000e+00 3.01060794e-08]\n",
      " [1.00121966e-07 9.99999881e-01]\n",
      " [9.97644007e-01 2.35597277e-03]\n",
      " [9.99959946e-01 4.00858626e-05]\n",
      " [2.37449876e-06 9.99997616e-01]\n",
      " [9.99984622e-01 1.54255249e-05]\n",
      " [9.22607768e-08 9.99999881e-01]\n",
      " [1.18180374e-07 9.99999881e-01]\n",
      " [9.99868512e-01 1.31466950e-04]\n",
      " [2.40705512e-03 9.97592866e-01]\n",
      " [9.99883056e-01 1.16922689e-04]\n",
      " [9.85836610e-03 9.90141690e-01]\n",
      " [9.24341917e-01 7.56580532e-02]\n",
      " [5.98019734e-02 9.40198064e-01]\n",
      " [7.58370902e-07 9.99999285e-01]\n",
      " [9.99974728e-01 2.52499212e-05]\n",
      " [1.07681276e-02 9.89231884e-01]\n",
      " [9.99999881e-01 1.33738766e-07]\n",
      " [3.26092326e-08 1.00000000e+00]\n",
      " [9.94148731e-01 5.85129205e-03]\n",
      " [5.79100966e-01 4.20899034e-01]\n",
      " [1.79527968e-04 9.99820530e-01]\n",
      " [1.62173013e-08 1.00000000e+00]\n",
      " [8.19775270e-09 1.00000000e+00]\n",
      " [1.73305452e-01 8.26694608e-01]\n",
      " [9.98920679e-01 1.07936421e-03]\n",
      " [5.73681900e-03 9.94263113e-01]\n",
      " [5.38678432e-06 9.99994636e-01]\n",
      " [9.99999285e-01 7.00945805e-07]\n",
      " [9.99999881e-01 6.46256098e-08]\n",
      " [9.99722779e-01 2.77167856e-04]\n",
      " [9.99989629e-01 1.03242892e-05]\n",
      " [1.22299998e-05 9.99987721e-01]\n",
      " [4.72163826e-01 5.27836204e-01]\n",
      " [9.99999523e-01 5.28317742e-07]\n",
      " [3.28081114e-06 9.99996662e-01]\n",
      " [1.00000000e+00 2.06523953e-08]\n",
      " [5.14392788e-03 9.94856000e-01]\n",
      " [1.00000000e+00 4.90101826e-08]\n",
      " [3.44835425e-05 9.99965549e-01]\n",
      " [1.02936086e-08 1.00000000e+00]\n",
      " [9.96978879e-01 3.02108843e-03]\n",
      " [9.99996066e-01 3.87473574e-06]\n",
      " [4.47033308e-08 1.00000000e+00]\n",
      " [9.79589045e-01 2.04109065e-02]\n",
      " [1.86607316e-08 1.00000000e+00]\n",
      " [2.48176875e-08 1.00000000e+00]\n",
      " [9.99966860e-01 3.31972260e-05]\n",
      " [8.97719204e-01 1.02280825e-01]\n",
      " [1.72152795e-05 9.99982834e-01]\n",
      " [3.73826295e-01 6.26173735e-01]\n",
      " [4.37887788e-01 5.62112212e-01]\n",
      " [2.84424896e-05 9.99971509e-01]\n",
      " [2.46201038e-01 7.53798962e-01]\n",
      " [9.99955773e-01 4.41952179e-05]\n",
      " [9.70365942e-01 2.96339840e-02]\n",
      " [9.99992013e-01 8.00557882e-06]\n",
      " [1.00000000e+00 2.35352644e-08]\n",
      " [6.34987606e-04 9.99365032e-01]\n",
      " [1.24594899e-05 9.99987483e-01]\n",
      " [1.49094410e-06 9.99998450e-01]\n",
      " [1.99073309e-08 1.00000000e+00]\n",
      " [2.02074091e-08 1.00000000e+00]\n",
      " [9.99982238e-01 1.77499733e-05]\n",
      " [1.81109590e-06 9.99998212e-01]\n",
      " [9.99997377e-01 2.61118112e-06]\n",
      " [4.15379927e-03 9.95846212e-01]\n",
      " [9.99977231e-01 2.27235250e-05]\n",
      " [1.00000000e+00 5.22952028e-08]\n",
      " [8.84040833e-01 1.15959100e-01]\n",
      " [4.90763874e-09 1.00000000e+00]\n",
      " [2.86389596e-08 1.00000000e+00]\n",
      " [3.18478036e-04 9.99681592e-01]\n",
      " [3.83930328e-08 1.00000000e+00]\n",
      " [9.89790738e-09 1.00000000e+00]\n",
      " [2.47300327e-01 7.52699673e-01]\n",
      " [9.07983456e-04 9.99091983e-01]\n",
      " [1.24414479e-08 1.00000000e+00]\n",
      " [2.69199376e-07 9.99999762e-01]\n",
      " [1.86449345e-08 1.00000000e+00]\n",
      " [1.00000000e+00 3.09446513e-09]\n",
      " [3.35242152e-01 6.64757848e-01]\n",
      " [9.99999523e-01 4.71346112e-07]\n",
      " [1.69551422e-05 9.99983072e-01]\n",
      " [9.99989748e-01 1.03003731e-05]\n",
      " [4.57043008e-08 1.00000000e+00]\n",
      " [5.96497239e-06 9.99994040e-01]\n",
      " [6.67071642e-09 1.00000000e+00]\n",
      " [8.09722678e-06 9.99991894e-01]\n",
      " [4.79558395e-04 9.99520421e-01]\n",
      " [7.95901179e-01 2.04098821e-01]\n",
      " [2.26120733e-07 9.99999762e-01]\n",
      " [1.00000000e+00 4.48755593e-08]\n",
      " [9.99999881e-01 6.43322835e-08]\n",
      " [3.93177383e-03 9.96068239e-01]\n",
      " [1.09062931e-02 9.89093781e-01]\n",
      " [9.94914055e-01 5.08592837e-03]\n",
      " [1.21527794e-03 9.98784721e-01]\n",
      " [9.99937177e-01 6.28198541e-05]\n",
      " [9.99999166e-01 7.78260187e-07]\n",
      " [2.75507574e-07 9.99999762e-01]\n",
      " [9.38051729e-04 9.99062002e-01]\n",
      " [1.43338684e-06 9.99998569e-01]\n",
      " [1.22092402e-07 9.99999881e-01]\n",
      " [2.12182385e-06 9.99997854e-01]\n",
      " [7.40383912e-05 9.99925971e-01]\n",
      " [7.91001824e-08 9.99999881e-01]\n",
      " [2.88695621e-04 9.99711335e-01]\n",
      " [9.99999881e-01 1.25647688e-07]\n",
      " [4.59544722e-08 1.00000000e+00]\n",
      " [8.81642476e-03 9.91183639e-01]\n",
      " [9.99999642e-01 3.16080957e-07]\n",
      " [7.13502595e-05 9.99928594e-01]\n",
      " [9.99894619e-01 1.05326071e-04]\n",
      " [1.12712616e-03 9.98872817e-01]\n",
      " [6.79862611e-09 1.00000000e+00]\n",
      " [1.62986087e-08 1.00000000e+00]\n",
      " [9.99999404e-01 6.05833577e-07]\n",
      " [9.99987960e-01 1.20858813e-05]\n",
      " [1.42106798e-03 9.98578906e-01]\n",
      " [9.97242570e-01 2.75742565e-03]\n",
      " [3.24313296e-05 9.99967575e-01]\n",
      " [2.05365013e-05 9.99979496e-01]\n",
      " [1.46977324e-03 9.98530269e-01]\n",
      " [9.99999881e-01 8.97886423e-08]\n",
      " [1.14388801e-02 9.88561094e-01]\n",
      " [9.99999523e-01 4.35802519e-07]\n",
      " [9.99999762e-01 2.17076106e-07]\n",
      " [2.02674622e-04 9.99797285e-01]\n",
      " [4.37515648e-03 9.95624840e-01]\n",
      " [7.66188357e-09 1.00000000e+00]\n",
      " [3.70086575e-08 1.00000000e+00]\n",
      " [1.00000000e+00 3.28034915e-08]\n",
      " [7.05135372e-09 1.00000000e+00]\n",
      " [8.71527731e-01 1.28472298e-01]\n",
      " [9.99999762e-01 2.55392791e-07]\n",
      " [2.20236592e-02 9.77976382e-01]\n",
      " [2.93790265e-07 9.99999762e-01]\n",
      " [2.37354811e-06 9.99997616e-01]\n",
      " [9.10267062e-09 1.00000000e+00]\n",
      " [6.54342532e-01 3.45657438e-01]\n",
      " [9.99986649e-01 1.33123294e-05]\n",
      " [4.55150015e-08 1.00000000e+00]\n",
      " [9.54963930e-09 1.00000000e+00]\n",
      " [9.99999404e-01 5.86634883e-07]\n",
      " [3.43007268e-05 9.99965668e-01]\n",
      " [6.33268158e-08 9.99999881e-01]\n",
      " [3.04710079e-06 9.99996901e-01]\n",
      " [5.54891154e-02 9.44510877e-01]\n",
      " [2.30467640e-06 9.99997735e-01]\n",
      " [3.22998647e-04 9.99677062e-01]\n",
      " [7.67865060e-09 1.00000000e+00]\n",
      " [2.70325452e-01 7.29674578e-01]\n",
      " [9.99997139e-01 2.82605311e-06]\n",
      " [9.99812067e-01 1.87960977e-04]\n",
      " [6.36132370e-07 9.99999404e-01]\n",
      " [9.99999762e-01 2.10049336e-07]\n",
      " [7.62898708e-05 9.99923706e-01]\n",
      " [3.72494391e-08 1.00000000e+00]\n",
      " [9.91812110e-01 8.18785559e-03]\n",
      " [9.89701867e-01 1.02981534e-02]\n",
      " [4.94610518e-04 9.99505401e-01]\n",
      " [9.99985218e-01 1.47524806e-05]\n",
      " [1.00000000e+00 1.26361668e-08]\n",
      " [9.99991059e-01 8.99829683e-06]\n",
      " [2.87283994e-02 9.71271634e-01]\n",
      " [3.12521384e-04 9.99687552e-01]\n",
      " [1.09835617e-06 9.99998927e-01]\n",
      " [4.12037728e-08 1.00000000e+00]\n",
      " [5.61291756e-07 9.99999404e-01]\n",
      " [8.69755070e-07 9.99999166e-01]\n",
      " [3.86030041e-02 9.61396992e-01]\n",
      " [8.40257215e-08 9.99999881e-01]\n",
      " [9.99997258e-01 2.74117997e-06]\n",
      " [5.85763082e-09 1.00000000e+00]\n",
      " [2.70222511e-08 1.00000000e+00]\n",
      " [6.34861522e-07 9.99999404e-01]\n",
      " [5.57519024e-06 9.99994397e-01]\n",
      " [2.71136523e-04 9.99728858e-01]\n",
      " [3.03585040e-07 9.99999642e-01]\n",
      " [9.99997973e-01 2.03791478e-06]\n",
      " [1.09120607e-04 9.99890924e-01]\n",
      " [9.99877095e-01 1.22936559e-04]\n",
      " [7.21469462e-01 2.78530568e-01]\n",
      " [9.99999881e-01 6.59443629e-08]\n",
      " [1.96440309e-01 8.03559721e-01]\n",
      " [9.99999881e-01 7.21023525e-08]\n",
      " [8.63897741e-01 1.36102259e-01]\n",
      " [9.99999881e-01 6.89774140e-08]\n",
      " [4.83002001e-03 9.95169938e-01]\n",
      " [9.99999642e-01 3.01399268e-07]\n",
      " [9.99999762e-01 2.16234127e-07]\n",
      " [9.95843112e-01 4.15688893e-03]\n",
      " [3.45386361e-05 9.99965429e-01]\n",
      " [1.00000000e+00 6.36924913e-09]\n",
      " [2.58774935e-06 9.99997377e-01]\n",
      " [9.99998569e-01 1.43923023e-06]\n",
      " [2.49738485e-04 9.99750316e-01]\n",
      " [2.45722339e-01 7.54277706e-01]\n",
      " [9.98169541e-01 1.83041207e-03]\n",
      " [9.99998927e-01 1.01528929e-06]\n",
      " [4.03904856e-08 1.00000000e+00]\n",
      " [4.84315425e-01 5.15684605e-01]\n",
      " [1.64995727e-03 9.98350024e-01]\n",
      " [1.00000000e+00 5.72268384e-08]\n",
      " [1.00000000e+00 3.92357862e-08]\n",
      " [6.66718814e-04 9.99333203e-01]\n",
      " [9.99044359e-01 9.55612632e-04]\n",
      " [3.48435969e-05 9.99965191e-01]\n",
      " [9.78384495e-01 2.16155313e-02]\n",
      " [5.55218005e-09 1.00000000e+00]\n",
      " [5.79524553e-08 1.00000000e+00]\n",
      " [5.63118258e-04 9.99436915e-01]\n",
      " [1.29060052e-08 1.00000000e+00]\n",
      " [9.99989748e-01 1.02527229e-05]\n",
      " [9.99997854e-01 2.19157982e-06]\n",
      " [1.63607852e-04 9.99836326e-01]\n",
      " [2.14145572e-08 1.00000000e+00]\n",
      " [9.98311520e-01 1.68845616e-03]\n",
      " [3.02738103e-04 9.99697328e-01]\n",
      " [9.98824894e-01 1.17508473e-03]\n",
      " [9.98095334e-01 1.90469471e-03]\n",
      " [9.81017016e-03 9.90189850e-01]\n",
      " [9.99999762e-01 2.64684076e-07]\n",
      " [2.55872821e-03 9.97441292e-01]\n",
      " [9.64729097e-09 1.00000000e+00]\n",
      " [9.99992967e-01 7.02437319e-06]\n",
      " [1.08428102e-08 1.00000000e+00]\n",
      " [9.99992967e-01 7.04002605e-06]\n",
      " [9.99797404e-01 2.02617055e-04]\n",
      " [9.99998093e-01 1.88278875e-06]\n",
      " [5.56127168e-03 9.94438767e-01]\n",
      " [3.35632241e-04 9.99664426e-01]\n",
      " [7.45957568e-02 9.25404251e-01]\n",
      " [1.16233450e-08 1.00000000e+00]\n",
      " [9.99999642e-01 3.32025820e-07]\n",
      " [7.63964534e-01 2.36035451e-01]\n",
      " [9.99506354e-01 4.93607309e-04]\n",
      " [9.99999881e-01 8.00445008e-08]\n",
      " [3.62468744e-03 9.96375263e-01]\n",
      " [9.99999881e-01 1.45022341e-07]\n",
      " [5.19542937e-07 9.99999523e-01]\n",
      " [8.89992151e-08 9.99999881e-01]\n",
      " [8.50100221e-08 9.99999881e-01]\n",
      " [1.39299803e-03 9.98606980e-01]\n",
      " [6.99800324e-08 9.99999881e-01]\n",
      " [4.55669127e-03 9.95443344e-01]\n",
      " [1.00776823e-02 9.89922345e-01]\n",
      " [4.35078852e-02 9.56492126e-01]\n",
      " [3.97509517e-04 9.99602497e-01]\n",
      " [3.05069407e-05 9.99969482e-01]\n",
      " [6.67564105e-04 9.99332368e-01]\n",
      " [1.83509255e-05 9.99981642e-01]\n",
      " [1.00000000e+00 2.71739999e-08]\n",
      " [9.23398090e-07 9.99999046e-01]\n",
      " [3.81267536e-03 9.96187389e-01]\n",
      " [1.39171883e-04 9.99860764e-01]\n",
      " [6.53550680e-09 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# test verilerinizi hazırlayın\n",
    "x_test = X_test\n",
    "\n",
    "# tahminleri yapın\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# tahmin sonuçlarını kontrol edin\n",
    "print(y_pred)  # (num_samples, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       258\n",
      "           1       0.73      0.87      0.79       242\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       500\n",
      "   macro avg       0.79      0.78      0.78       500\n",
      "weighted avg       0.79      0.78      0.78       500\n",
      " samples avg       0.78      0.78      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "def video_show(single_video):\n",
    "    # Video yolu\n",
    "    video_path = single_video\n",
    "\n",
    "    # Video yükleyici\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # GIF oluşturucu\n",
    "    gif_frames = []\n",
    "\n",
    "    # Video frame'lerini okuma ve GIF'e ekleme\n",
    "    while True:\n",
    "        # Frame okuma\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Eğer frame okunamadıysa döngüden çık\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Frame'i BGR'den RGB'ye dönüştürme\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Frame'i GIF'e ekleme\n",
    "        gif_frames.append(frame_rgb)\n",
    "\n",
    "    # Kaynakları serbest bırakma\n",
    "    cap.release()\n",
    "\n",
    "    # GIF dosyasını oluşturma\n",
    "    imageio.mimsave(\"video.gif\", gif_frames, fps=30)\n",
    "\n",
    "def predict(frames):\n",
    "    frames = [frames] \n",
    "    frames = np.array(frames)\n",
    "    y_pred = model.predict(frames)\n",
    "\n",
    "    # tahmin sonuçlarını kontrol edin\n",
    "   \n",
    "    predictions = y_pred > 0.5\n",
    "    print(predictions)  # (num_samples, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_show(videos[1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "[[False  True]]\n"
     ]
    }
   ],
   "source": [
    "predict(x_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
