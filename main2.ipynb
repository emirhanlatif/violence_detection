{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import imageio\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"hockey_fight_videos\"\n",
    "BATCH_SIZE = 64\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (36, 28, 28, 3)\n",
    "NUM_CLASSES = 2\n",
    "LABELS = [\"no\",\"fi\"]\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0.00001\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 100\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (8, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# veri kümenizi yükleyin\n",
    "data_path = \"C:/Users/Emirhan/Downloads/data\"\n",
    "classes = os.listdir(data_path)\n",
    "\n",
    "videos = []\n",
    "labels = []\n",
    "train_files = []\n",
    "val_files = []\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(data_path, cls)\n",
    "    files = os.listdir(cls_path)\n",
    "    for video in os.listdir(cls_path):\n",
    "        video_path = os.path.join(cls_path, video)\n",
    "        videos.append(video_path)\n",
    "        label = os.path.basename(video_path).split('_')[0][0:2]\n",
    "        if label not in LABELS:\n",
    "            continue\n",
    "        labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "videos = np.array(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emirhan\\anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Örnek veri etiketleri\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels = encoder.fit_transform(np.array(labels).reshape(-1, 1))\n",
    "\n",
    "# Kodlanmış etiketleri kontrol etme\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 36, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Videoların yollarını içeren bir liste oluşturma\n",
    "video_paths = videos\n",
    "\n",
    "# En kısa video uzunluğunu belirleme\n",
    "min_frame_count = float('inf')\n",
    "\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count < min_frame_count:\n",
    "        min_frame_count = frame_count\n",
    "\n",
    "# Tüm videolardan aynı sayıda frame almak için döngü\n",
    "frames = []\n",
    "\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    selected_frames = []\n",
    "    for i in range(min_frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (28,28))\n",
    "            selected_frames.append(frame)\n",
    "    frames.append(np.array(selected_frames))\n",
    "\n",
    "# Tüm videolardaki ortak frame sayısına sahip bir matris oluşturma\n",
    "video_array = np.stack(frames)\n",
    "\n",
    "# Video dizisinin şeklini yazdırma\n",
    "print(video_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(video_array, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = \"train\",\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "trainloader = prepare_dataloader(X_train, y_train, \"train\")\n",
    "validloader = prepare_dataloader(X_val, y_val, \"valid\")\n",
    "testloader = prepare_dataloader(X_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 36, 28, 28, 3, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUBELET EMBEDDING\n",
    "\n",
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIONAL \n",
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 13s 155ms/step - loss: 0.7758 - accuracy: 0.5044 - val_loss: 1.0108 - val_accuracy: 0.4733\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6881 - accuracy: 0.5415 - val_loss: 1.1319 - val_accuracy: 0.4733\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6785 - accuracy: 0.5815 - val_loss: 1.1730 - val_accuracy: 0.4733\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6698 - accuracy: 0.6007 - val_loss: 1.1573 - val_accuracy: 0.4733\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6889 - accuracy: 0.5489 - val_loss: 1.2920 - val_accuracy: 0.4733\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6429 - accuracy: 0.6281 - val_loss: 1.3644 - val_accuracy: 0.4733\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5886 - accuracy: 0.6696 - val_loss: 1.6922 - val_accuracy: 0.4733\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5797 - accuracy: 0.6778 - val_loss: 1.6066 - val_accuracy: 0.4733\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5422 - accuracy: 0.6889 - val_loss: 1.5099 - val_accuracy: 0.4733\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5149 - accuracy: 0.7141 - val_loss: 1.4182 - val_accuracy: 0.4733\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5578 - accuracy: 0.6859 - val_loss: 1.6175 - val_accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4950 - accuracy: 0.7363 - val_loss: 1.4680 - val_accuracy: 0.4733\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4935 - accuracy: 0.7281 - val_loss: 1.5201 - val_accuracy: 0.4733\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4646 - accuracy: 0.7385 - val_loss: 1.6815 - val_accuracy: 0.4733\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4475 - accuracy: 0.7630 - val_loss: 1.6638 - val_accuracy: 0.4733\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4811 - accuracy: 0.7356 - val_loss: 1.5649 - val_accuracy: 0.4733\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4285 - accuracy: 0.7719 - val_loss: 1.5561 - val_accuracy: 0.4733\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4107 - accuracy: 0.7770 - val_loss: 1.8241 - val_accuracy: 0.4733\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3980 - accuracy: 0.7830 - val_loss: 2.0411 - val_accuracy: 0.4733\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3986 - accuracy: 0.7867 - val_loss: 2.1795 - val_accuracy: 0.4733\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4170 - accuracy: 0.7785 - val_loss: 2.0401 - val_accuracy: 0.4733\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3867 - accuracy: 0.7941 - val_loss: 1.9611 - val_accuracy: 0.4733\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3576 - accuracy: 0.8207 - val_loss: 2.5361 - val_accuracy: 0.4733\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3309 - accuracy: 0.8333 - val_loss: 2.8987 - val_accuracy: 0.4733\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3281 - accuracy: 0.8319 - val_loss: 2.8517 - val_accuracy: 0.4733\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3208 - accuracy: 0.8215 - val_loss: 3.1563 - val_accuracy: 0.4733\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3128 - accuracy: 0.8415 - val_loss: 3.1573 - val_accuracy: 0.4733\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3074 - accuracy: 0.8393 - val_loss: 3.2008 - val_accuracy: 0.4733\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3359 - accuracy: 0.8074 - val_loss: 3.2160 - val_accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2930 - accuracy: 0.8548 - val_loss: 3.4346 - val_accuracy: 0.4733\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3050 - accuracy: 0.8422 - val_loss: 3.4909 - val_accuracy: 0.4733\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2929 - accuracy: 0.8526 - val_loss: 3.6098 - val_accuracy: 0.4733\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2737 - accuracy: 0.8659 - val_loss: 3.6357 - val_accuracy: 0.4733\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2606 - accuracy: 0.8637 - val_loss: 3.8770 - val_accuracy: 0.4733\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2569 - accuracy: 0.8667 - val_loss: 3.8104 - val_accuracy: 0.4733\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3865 - accuracy: 0.8074 - val_loss: 3.9023 - val_accuracy: 0.4733\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2567 - accuracy: 0.8689 - val_loss: 3.9191 - val_accuracy: 0.4733\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 4.0496 - val_accuracy: 0.4733\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2819 - accuracy: 0.8541 - val_loss: 4.0346 - val_accuracy: 0.4733\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2159 - accuracy: 0.9015 - val_loss: 4.1400 - val_accuracy: 0.4733\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1897 - accuracy: 0.9126 - val_loss: 4.2278 - val_accuracy: 0.4733\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2272 - accuracy: 0.9007 - val_loss: 4.0179 - val_accuracy: 0.4733\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.2156 - accuracy: 0.8896 - val_loss: 3.9696 - val_accuracy: 0.4733\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1861 - accuracy: 0.9185 - val_loss: 4.1560 - val_accuracy: 0.4733\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1542 - accuracy: 0.9333 - val_loss: 4.3081 - val_accuracy: 0.4733\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1744 - accuracy: 0.9244 - val_loss: 4.3773 - val_accuracy: 0.4733\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1353 - accuracy: 0.9437 - val_loss: 4.4008 - val_accuracy: 0.4733\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1511 - accuracy: 0.9393 - val_loss: 4.3767 - val_accuracy: 0.4733\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1060 - accuracy: 0.9519 - val_loss: 4.4553 - val_accuracy: 0.4733\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.1890 - accuracy: 0.9207 - val_loss: 4.3407 - val_accuracy: 0.4733\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1232 - accuracy: 0.9504 - val_loss: 4.4799 - val_accuracy: 0.4733\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0969 - accuracy: 0.9711 - val_loss: 4.5288 - val_accuracy: 0.4733\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1603 - accuracy: 0.9407 - val_loss: 4.2821 - val_accuracy: 0.4733\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1338 - accuracy: 0.9422 - val_loss: 4.2929 - val_accuracy: 0.4733\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0736 - accuracy: 0.9719 - val_loss: 4.4920 - val_accuracy: 0.4733\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3121 - accuracy: 0.8437 - val_loss: 3.9773 - val_accuracy: 0.4733\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2497 - accuracy: 0.8852 - val_loss: 4.2769 - val_accuracy: 0.4733\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1910 - accuracy: 0.9237 - val_loss: 4.3404 - val_accuracy: 0.4733\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1358 - accuracy: 0.9474 - val_loss: 4.4994 - val_accuracy: 0.4733\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.1379 - accuracy: 0.9437 - val_loss: 4.4924 - val_accuracy: 0.4733\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1099 - accuracy: 0.9548 - val_loss: 4.5857 - val_accuracy: 0.4733\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0938 - accuracy: 0.9622 - val_loss: 4.6172 - val_accuracy: 0.4733\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0721 - accuracy: 0.9704 - val_loss: 4.6920 - val_accuracy: 0.4733\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0642 - accuracy: 0.9726 - val_loss: 4.7450 - val_accuracy: 0.4733\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0899 - accuracy: 0.9615 - val_loss: 4.6956 - val_accuracy: 0.4733\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0639 - accuracy: 0.9756 - val_loss: 4.7149 - val_accuracy: 0.4733\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 4.7327 - val_accuracy: 0.4733\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0583 - accuracy: 0.9778 - val_loss: 4.7815 - val_accuracy: 0.4733\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0282 - accuracy: 0.9926 - val_loss: 4.8895 - val_accuracy: 0.4733\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 4.9005 - val_accuracy: 0.4733\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 4.9174 - val_accuracy: 0.4733\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 4.9468 - val_accuracy: 0.4733\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 4.9668 - val_accuracy: 0.4733\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0623 - accuracy: 0.9830 - val_loss: 4.7799 - val_accuracy: 0.4733\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0292 - accuracy: 0.9867 - val_loss: 4.8485 - val_accuracy: 0.4733\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 4.9129 - val_accuracy: 0.4733\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 4.9630 - val_accuracy: 0.4733\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0825 - accuracy: 0.9659 - val_loss: 4.7393 - val_accuracy: 0.4733\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 4.7713 - val_accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 4.9335 - val_accuracy: 0.4733\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.0234 - accuracy: 0.9904 - val_loss: 5.0330 - val_accuracy: 0.4733\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 5.0029 - val_accuracy: 0.4733\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0225 - accuracy: 0.9911 - val_loss: 5.0182 - val_accuracy: 0.4733\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 5.0693 - val_accuracy: 0.4733\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 4.9736 - val_accuracy: 0.4733\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 5.0023 - val_accuracy: 0.4733\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 4.9957 - val_accuracy: 0.4733\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0304 - accuracy: 0.9837 - val_loss: 5.0765 - val_accuracy: 0.4733\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 5.0943 - val_accuracy: 0.4733\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 5.1680 - val_accuracy: 0.4733\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 5.1495 - val_accuracy: 0.4733\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0698 - accuracy: 0.9793 - val_loss: 4.9988 - val_accuracy: 0.4733\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 5.0290 - val_accuracy: 0.4733\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 5.0698 - val_accuracy: 0.4733\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0202 - accuracy: 0.9896 - val_loss: 5.1000 - val_accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 4.9668 - val_accuracy: 0.4733\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0312 - accuracy: 0.9881 - val_loss: 5.0212 - val_accuracy: 0.4733\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 5.1151 - val_accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 5.0741 - val_accuracy: 0.4733\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 5.0334 - val_accuracy: 0.4733\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    # Initialize model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy'\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 36, 28, 28,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " tubelet_embedding (TubeletEmbe  (None, 36, 128)     196736      ['input_1[0][0]']                \n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " positional_encoder (Positional  (None, 36, 128)     4608        ['tubelet_embedding[0][0]']      \n",
      " Encoder)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 36, 128)     256         ['positional_encoder[0][0]']     \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 36, 128)     66048       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 36, 128)      0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'positional_encoder[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 36, 128)     256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 36, 128)      131712      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 36, 128)      0           ['sequential[0][0]',             \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 36, 128)     256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 36, 128)     66048       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 36, 128)      0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 36, 128)     256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 36, 128)      0           ['sequential_1[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 36, 128)     256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 36, 128)     66048       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 36, 128)      0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 36, 128)     256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 36, 128)      0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 36, 128)     256         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 36, 128)     66048       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 36, 128)      0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 36, 128)     256         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 36, 128)      0           ['sequential_3[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 36, 128)     256         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 36, 128)     66048       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 36, 128)      0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 36, 128)     256         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 36, 128)      0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 36, 128)     256         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 36, 128)     66048       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 36, 128)      0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 36, 128)     256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 36, 128)      0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 36, 128)     256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 36, 128)     66048       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 36, 128)      0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 36, 128)     256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 36, 128)      0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 36, 128)     256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 36, 128)     66048       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 36, 128)      0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 36, 128)     256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 36, 128)      131712      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 36, 128)      0           ['sequential_7[0][0]',           \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 36, 128)     256         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_16[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 2)            258         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,788,034\n",
      "Trainable params: 1,788,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 25ms/step\n",
      "[[2.69670831e-03 9.97303247e-01]\n",
      " [9.99168515e-01 8.31523445e-04]\n",
      " [1.05719780e-08 1.00000000e+00]\n",
      " [8.21080505e-07 9.99999166e-01]\n",
      " [9.99998212e-01 1.84591852e-06]\n",
      " [1.04945047e-05 9.99989510e-01]\n",
      " [6.91660702e-08 9.99999881e-01]\n",
      " [1.08192175e-08 1.00000000e+00]\n",
      " [3.93956618e-08 1.00000000e+00]\n",
      " [5.40579720e-07 9.99999404e-01]\n",
      " [9.99996543e-01 3.46069555e-06]\n",
      " [1.00000000e+00 7.24425364e-09]\n",
      " [6.22022152e-01 3.77977848e-01]\n",
      " [1.22987993e-08 1.00000000e+00]\n",
      " [1.25653719e-06 9.99998689e-01]\n",
      " [1.00000000e+00 5.29912256e-08]\n",
      " [9.99999881e-01 1.45588842e-07]\n",
      " [9.99991536e-01 8.49507251e-06]\n",
      " [1.00000000e+00 1.52039448e-08]\n",
      " [1.60093039e-01 8.39906991e-01]\n",
      " [9.99933720e-01 6.62864986e-05]\n",
      " [3.98516469e-03 9.96014833e-01]\n",
      " [1.00000000e+00 1.89737293e-08]\n",
      " [1.30095596e-05 9.99987006e-01]\n",
      " [8.44363630e-01 1.55636430e-01]\n",
      " [5.97558085e-07 9.99999404e-01]\n",
      " [1.00000000e+00 1.04922684e-08]\n",
      " [1.00000000e+00 2.04176267e-08]\n",
      " [9.99999166e-01 7.99895361e-07]\n",
      " [1.66090715e-08 1.00000000e+00]\n",
      " [5.73350576e-07 9.99999404e-01]\n",
      " [1.58774199e-07 9.99999881e-01]\n",
      " [5.15884402e-08 1.00000000e+00]\n",
      " [1.00000000e+00 6.16930951e-09]\n",
      " [9.80282426e-01 1.97175685e-02]\n",
      " [1.00000000e+00 4.77880757e-09]\n",
      " [9.99999285e-01 7.19319530e-07]\n",
      " [1.00000000e+00 7.88452947e-09]\n",
      " [1.00000000e+00 5.17778105e-08]\n",
      " [9.12202418e-01 8.77975747e-02]\n",
      " [1.00000000e+00 5.09735854e-09]\n",
      " [9.99998689e-01 1.36020799e-06]\n",
      " [1.36464946e-08 1.00000000e+00]\n",
      " [6.56231549e-08 9.99999881e-01]\n",
      " [1.15292164e-06 9.99998808e-01]\n",
      " [2.38566980e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.59114650e-08]\n",
      " [9.99997616e-01 2.41456155e-06]\n",
      " [3.54450975e-07 9.99999642e-01]\n",
      " [1.00000000e+00 5.24612132e-09]\n",
      " [1.89804243e-08 1.00000000e+00]\n",
      " [1.00000000e+00 4.32130740e-08]\n",
      " [1.00000000e+00 1.80873929e-08]\n",
      " [2.02976445e-08 1.00000000e+00]\n",
      " [3.79437804e-01 6.20562196e-01]\n",
      " [9.99999881e-01 1.02042378e-07]\n",
      " [1.00000000e+00 8.80727669e-09]\n",
      " [3.96238534e-07 9.99999642e-01]\n",
      " [2.81821599e-06 9.99997139e-01]\n",
      " [9.99997973e-01 2.05346942e-06]\n",
      " [9.99283850e-01 7.16132054e-04]\n",
      " [1.62707767e-08 1.00000000e+00]\n",
      " [9.99999404e-01 5.65320761e-07]\n",
      " [3.30159055e-05 9.99966979e-01]\n",
      " [4.64946171e-03 9.95350480e-01]\n",
      " [7.50511958e-07 9.99999285e-01]\n",
      " [9.06085670e-01 9.39143971e-02]\n",
      " [1.02375699e-08 1.00000000e+00]\n",
      " [4.58856672e-01 5.41143358e-01]\n",
      " [9.99982595e-01 1.73814660e-05]\n",
      " [3.62256140e-01 6.37743890e-01]\n",
      " [1.00000000e+00 4.66370143e-09]\n",
      " [9.95383544e-08 9.99999881e-01]\n",
      " [3.78060250e-08 1.00000000e+00]\n",
      " [1.00000000e+00 6.70083633e-09]\n",
      " [9.76533101e-07 9.99999046e-01]\n",
      " [1.00000000e+00 1.34657103e-08]\n",
      " [9.85593488e-07 9.99999046e-01]\n",
      " [2.22967756e-07 9.99999762e-01]\n",
      " [1.00000000e+00 1.36819400e-08]\n",
      " [9.27860092e-05 9.99907255e-01]\n",
      " [1.00000000e+00 3.36277939e-09]\n",
      " [1.00000000e+00 1.79979871e-08]\n",
      " [1.61064178e-01 8.38935792e-01]\n",
      " [2.47617535e-08 1.00000000e+00]\n",
      " [9.99885082e-01 1.14908064e-04]\n",
      " [6.54811680e-04 9.99345124e-01]\n",
      " [6.56987960e-03 9.93430078e-01]\n",
      " [2.61946589e-08 1.00000000e+00]\n",
      " [3.25159371e-01 6.74840629e-01]\n",
      " [1.38874876e-08 1.00000000e+00]\n",
      " [6.58756912e-01 3.41243118e-01]\n",
      " [1.00000000e+00 8.07948375e-09]\n",
      " [1.34702759e-05 9.99986529e-01]\n",
      " [3.57459911e-08 1.00000000e+00]\n",
      " [9.99774873e-01 2.25184558e-04]\n",
      " [2.00635437e-08 1.00000000e+00]\n",
      " [1.33887706e-05 9.99986649e-01]\n",
      " [1.95333466e-01 8.04666519e-01]\n",
      " [4.99716550e-02 9.50028360e-01]\n",
      " [5.00269870e-08 1.00000000e+00]\n",
      " [9.99984264e-01 1.57780178e-05]\n",
      " [5.86203761e-08 1.00000000e+00]\n",
      " [3.75210278e-04 9.99624729e-01]\n",
      " [1.00000000e+00 5.94145213e-08]\n",
      " [1.00000000e+00 5.69815590e-08]\n",
      " [9.99997735e-01 2.30044725e-06]\n",
      " [9.99892831e-01 1.07179563e-04]\n",
      " [9.99999881e-01 1.34751971e-07]\n",
      " [1.00000000e+00 1.11222560e-08]\n",
      " [1.00000000e+00 2.87858928e-08]\n",
      " [3.00602920e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.21278977e-08]\n",
      " [9.99952674e-01 4.73511864e-05]\n",
      " [4.49393428e-06 9.99995470e-01]\n",
      " [1.00000000e+00 3.86479604e-09]\n",
      " [9.99999881e-01 1.48808454e-07]\n",
      " [1.04688800e-08 1.00000000e+00]\n",
      " [8.54740094e-04 9.99145269e-01]\n",
      " [1.00000000e+00 7.28868832e-09]\n",
      " [5.79855111e-07 9.99999404e-01]\n",
      " [4.58815508e-02 9.54118371e-01]\n",
      " [9.99976039e-01 2.39898800e-05]\n",
      " [1.00000000e+00 5.76171857e-08]\n",
      " [2.54634180e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.58105369e-08]\n",
      " [1.13972112e-06 9.99998808e-01]\n",
      " [2.55471036e-06 9.99997497e-01]\n",
      " [9.99937057e-01 6.28797789e-05]\n",
      " [2.64968839e-05 9.99973536e-01]\n",
      " [1.00000000e+00 4.57393368e-09]\n",
      " [9.99997735e-01 2.24817586e-06]\n",
      " [1.00000000e+00 1.52601629e-08]\n",
      " [1.27109146e-07 9.99999881e-01]\n",
      " [2.86938220e-01 7.13061810e-01]\n",
      " [3.72572551e-08 1.00000000e+00]\n",
      " [9.99922514e-01 7.75081717e-05]\n",
      " [9.99999881e-01 7.31024343e-08]\n",
      " [1.00000000e+00 5.03546493e-09]\n",
      " [1.00000000e+00 7.55177787e-09]\n",
      " [1.00000000e+00 1.49943755e-08]\n",
      " [9.99779880e-01 2.20133792e-04]\n",
      " [1.00000000e+00 6.48749277e-09]\n",
      " [1.55209463e-08 1.00000000e+00]\n",
      " [5.48322080e-03 9.94516790e-01]\n",
      " [1.00000000e+00 9.26013577e-09]\n",
      " [9.99809444e-01 1.90527178e-04]\n",
      " [9.84700513e-04 9.99015331e-01]\n",
      " [1.00000000e+00 8.47701909e-09]\n",
      " [1.00000000e+00 8.02661493e-09]\n",
      " [1.00000000e+00 7.41262385e-09]\n",
      " [8.99425328e-01 1.00574724e-01]\n",
      " [3.35417092e-02 9.66458321e-01]\n",
      " [5.96568907e-06 9.99994040e-01]\n",
      " [1.17061213e-02 9.88293886e-01]\n",
      " [1.15102337e-08 1.00000000e+00]\n",
      " [1.00000000e+00 9.04595243e-09]\n",
      " [9.99999046e-01 9.70050451e-07]\n",
      " [9.99971986e-01 2.80459863e-05]\n",
      " [9.99982595e-01 1.73814660e-05]\n",
      " [1.24592646e-07 9.99999881e-01]\n",
      " [1.12875411e-03 9.98871267e-01]\n",
      " [1.00000000e+00 5.53802915e-09]\n",
      " [9.99997973e-01 1.99503029e-06]\n",
      " [5.42407724e-05 9.99945760e-01]\n",
      " [9.87288713e-01 1.27112791e-02]\n",
      " [1.21221282e-08 1.00000000e+00]\n",
      " [1.00000000e+00 4.41623875e-08]\n",
      " [2.47866065e-08 1.00000000e+00]\n",
      " [1.77309103e-02 9.82269168e-01]\n",
      " [3.21109042e-07 9.99999642e-01]\n",
      " [1.59203832e-08 1.00000000e+00]\n",
      " [2.61407621e-07 9.99999762e-01]\n",
      " [2.45317811e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.55768216e-08]\n",
      " [2.98941700e-07 9.99999642e-01]\n",
      " [9.99116600e-01 8.83441069e-04]\n",
      " [1.00000000e+00 1.82083006e-08]\n",
      " [1.00000000e+00 1.52234740e-08]\n",
      " [9.81466830e-01 1.85331143e-02]\n",
      " [1.00000000e+00 8.34702796e-09]\n",
      " [9.99996662e-01 3.31322190e-06]\n",
      " [2.62498861e-06 9.99997377e-01]\n",
      " [9.28850966e-07 9.99999046e-01]\n",
      " [1.00000000e+00 1.47178820e-08]\n",
      " [1.00000000e+00 2.41383713e-08]\n",
      " [1.00000000e+00 1.88870732e-08]\n",
      " [1.54139741e-08 1.00000000e+00]\n",
      " [1.17122516e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.68532921e-08]\n",
      " [1.00000000e+00 6.16740392e-09]\n",
      " [1.00000000e+00 7.55234009e-09]\n",
      " [1.20172638e-06 9.99998808e-01]\n",
      " [1.00000000e+00 1.60360383e-08]\n",
      " [1.18971455e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.69379452e-09]\n",
      " [1.00000000e+00 9.60945989e-09]\n",
      " [1.00000000e+00 1.17451586e-08]\n",
      " [9.99996185e-01 3.79301832e-06]\n",
      " [9.76476073e-01 2.35239491e-02]\n",
      " [2.61819769e-05 9.99973774e-01]\n",
      " [1.00000000e+00 7.38425987e-09]\n",
      " [9.93827641e-01 6.17234036e-03]\n",
      " [4.18400577e-06 9.99995828e-01]\n",
      " [9.99987125e-01 1.28282572e-05]\n",
      " [1.00000000e+00 1.89006588e-08]\n",
      " [2.69900625e-07 9.99999762e-01]\n",
      " [1.46040158e-08 1.00000000e+00]\n",
      " [1.24672459e-08 1.00000000e+00]\n",
      " [9.99998331e-01 1.69353552e-06]\n",
      " [1.00000000e+00 1.62004223e-08]\n",
      " [1.00000000e+00 1.14330403e-08]\n",
      " [9.99948740e-01 5.12832703e-05]\n",
      " [3.90492380e-03 9.96095121e-01]\n",
      " [9.99993920e-01 6.11038831e-06]\n",
      " [1.00000000e+00 1.08354081e-08]\n",
      " [1.05693766e-06 9.99998927e-01]\n",
      " [1.24949089e-03 9.98750448e-01]\n",
      " [1.00000000e+00 7.89316612e-09]\n",
      " [9.99970436e-01 2.95970349e-05]\n",
      " [1.00000000e+00 3.49757778e-09]\n",
      " [1.00000000e+00 2.27422596e-08]\n",
      " [1.00000000e+00 3.64863553e-08]\n",
      " [9.99999762e-01 2.56502915e-07]\n",
      " [1.00000000e+00 2.53788563e-08]\n",
      " [1.00000000e+00 2.26457342e-08]\n",
      " [6.65954403e-08 9.99999881e-01]\n",
      " [9.99999523e-01 4.78534105e-07]\n",
      " [1.46319064e-06 9.99998569e-01]\n",
      " [6.31065191e-08 9.99999881e-01]\n",
      " [9.99999881e-01 9.75686234e-08]\n",
      " [9.99991059e-01 8.88506202e-06]\n",
      " [1.96819361e-08 1.00000000e+00]\n",
      " [1.00000000e+00 7.69110908e-09]\n",
      " [1.00000000e+00 9.95793403e-09]\n",
      " [3.13770106e-05 9.99968648e-01]\n",
      " [9.99993443e-01 6.52232393e-06]\n",
      " [1.00000000e+00 1.53019588e-08]\n",
      " [4.81884126e-05 9.99951839e-01]\n",
      " [1.00000000e+00 8.06307376e-09]\n",
      " [1.03493996e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.57882969e-08]\n",
      " [1.87186072e-06 9.99998093e-01]\n",
      " [7.68863018e-09 1.00000000e+00]\n",
      " [1.00000000e+00 2.45264831e-09]\n",
      " [2.35611136e-04 9.99764383e-01]\n",
      " [9.41014321e-07 9.99999046e-01]\n",
      " [1.00000000e+00 2.52798191e-08]\n",
      " [9.99998212e-01 1.76797130e-06]\n",
      " [4.12559029e-06 9.99995828e-01]\n",
      " [1.00000000e+00 7.91659716e-09]\n",
      " [9.99999523e-01 5.29983026e-07]\n",
      " [1.00000000e+00 6.82830814e-09]\n",
      " [9.99998331e-01 1.70925159e-06]\n",
      " [1.00000000e+00 3.14636424e-08]\n",
      " [1.24974482e-04 9.99875069e-01]\n",
      " [9.99997377e-01 2.67381233e-06]\n",
      " [1.14144595e-05 9.99988556e-01]\n",
      " [9.99998331e-01 1.66546499e-06]\n",
      " [1.00000000e+00 2.24484271e-08]\n",
      " [1.26919813e-05 9.99987364e-01]\n",
      " [1.49507741e-07 9.99999881e-01]\n",
      " [8.80405580e-08 9.99999881e-01]\n",
      " [2.51074653e-06 9.99997497e-01]\n",
      " [1.00000000e+00 4.48722837e-09]\n",
      " [1.50017847e-08 1.00000000e+00]\n",
      " [1.00000000e+00 6.14708640e-09]\n",
      " [7.78925751e-05 9.99922156e-01]\n",
      " [3.23443413e-01 6.76556587e-01]\n",
      " [9.99992847e-01 7.16420027e-06]\n",
      " [4.71448622e-08 1.00000000e+00]\n",
      " [8.97406771e-09 1.00000000e+00]\n",
      " [9.99999881e-01 8.16025292e-08]\n",
      " [1.00000000e+00 6.05841421e-09]\n",
      " [2.63477489e-07 9.99999762e-01]\n",
      " [9.98354733e-01 1.64526387e-03]\n",
      " [1.00000000e+00 5.53808155e-09]\n",
      " [1.00000000e+00 1.09365672e-08]\n",
      " [3.82661156e-08 1.00000000e+00]\n",
      " [3.68681754e-07 9.99999642e-01]\n",
      " [9.99995708e-01 4.23574829e-06]\n",
      " [4.07124171e-03 9.95928705e-01]\n",
      " [9.99963999e-01 3.60013437e-05]\n",
      " [1.00000000e+00 9.11561493e-09]\n",
      " [1.00000000e+00 8.94496477e-09]\n",
      " [9.99889612e-01 1.10370951e-04]\n",
      " [1.00000000e+00 1.73091212e-08]\n",
      " [9.99955058e-01 4.49419240e-05]\n",
      " [5.01047168e-08 1.00000000e+00]\n",
      " [1.00000000e+00 4.90443819e-09]\n",
      " [1.00000000e+00 3.16757180e-08]\n",
      " [1.00000000e+00 2.77078294e-09]\n",
      " [1.00000000e+00 6.18751672e-09]\n",
      " [6.11189067e-01 3.88810933e-01]\n",
      " [9.91695702e-01 8.30436312e-03]\n",
      " [9.99903560e-01 9.63747952e-05]\n",
      " [1.00000000e+00 1.45176706e-08]\n",
      " [1.00000000e+00 4.92421615e-09]\n",
      " [8.74872967e-07 9.99999166e-01]\n",
      " [1.40720564e-08 1.00000000e+00]\n",
      " [1.00000000e+00 7.57030971e-09]\n",
      " [2.33888222e-05 9.99976635e-01]\n",
      " [1.00000000e+00 1.69560828e-08]\n",
      " [1.00000000e+00 5.99567107e-09]\n",
      " [1.00000000e+00 1.80786675e-08]\n",
      " [3.76733780e-01 6.23266220e-01]\n",
      " [1.75603603e-07 9.99999881e-01]\n",
      " [9.99984026e-01 1.59459541e-05]\n",
      " [1.40886529e-08 1.00000000e+00]\n",
      " [5.63787726e-05 9.99943614e-01]\n",
      " [1.00000000e+00 3.45395783e-08]\n",
      " [3.76763091e-05 9.99962330e-01]\n",
      " [1.00000000e+00 6.24184127e-09]\n",
      " [9.99997497e-01 2.44632929e-06]\n",
      " [1.00000000e+00 8.85285178e-09]\n",
      " [1.16856290e-06 9.99998808e-01]\n",
      " [1.00000000e+00 4.50144348e-08]\n",
      " [1.00000000e+00 9.22956023e-09]\n",
      " [3.92395683e-04 9.99607623e-01]\n",
      " [9.95441556e-01 4.55841981e-03]\n",
      " [8.46890330e-01 1.53109699e-01]\n",
      " [1.02729985e-07 9.99999881e-01]\n",
      " [1.05526778e-08 1.00000000e+00]\n",
      " [1.43375188e-01 8.56624782e-01]\n",
      " [1.23223982e-08 1.00000000e+00]\n",
      " [9.99240994e-01 7.59030925e-04]\n",
      " [7.28982165e-02 9.27101791e-01]\n",
      " [1.00000000e+00 3.27483534e-08]\n",
      " [1.54192312e-05 9.99984622e-01]\n",
      " [7.10069025e-06 9.99992847e-01]\n",
      " [1.00000000e+00 8.37008063e-09]\n",
      " [1.00000000e+00 4.93051244e-09]\n",
      " [2.54675592e-06 9.99997497e-01]\n",
      " [4.74575586e-07 9.99999523e-01]\n",
      " [1.00000000e+00 1.59086664e-08]\n",
      " [9.99999762e-01 1.84503691e-07]\n",
      " [1.00000000e+00 8.76541417e-09]\n",
      " [7.84863971e-07 9.99999166e-01]\n",
      " [9.99999881e-01 7.81270657e-08]\n",
      " [1.00000000e+00 4.93610219e-09]\n",
      " [1.26888908e-08 1.00000000e+00]\n",
      " [9.99999762e-01 2.14888033e-07]\n",
      " [1.00000000e+00 3.25285243e-09]\n",
      " [1.00000000e+00 8.71762840e-09]\n",
      " [9.99998689e-01 1.27813598e-06]\n",
      " [1.00000000e+00 1.86974276e-08]\n",
      " [9.99993563e-01 6.43148314e-06]\n",
      " [1.05148663e-08 1.00000000e+00]\n",
      " [4.09148733e-08 1.00000000e+00]\n",
      " [9.99999166e-01 8.80135019e-07]\n",
      " [3.30776757e-08 1.00000000e+00]\n",
      " [3.23479563e-01 6.76520467e-01]\n",
      " [1.00000000e+00 1.09041158e-08]\n",
      " [8.69076103e-02 9.13092375e-01]\n",
      " [1.00000000e+00 3.63279429e-09]\n",
      " [2.58840007e-08 1.00000000e+00]\n",
      " [9.99999881e-01 1.18106243e-07]\n",
      " [1.00000000e+00 3.99791311e-08]\n",
      " [9.99865055e-01 1.34949412e-04]\n",
      " [1.00000000e+00 5.74648489e-08]\n",
      " [6.53433672e-04 9.99346554e-01]\n",
      " [1.00000000e+00 3.98901445e-09]\n",
      " [4.07649338e-07 9.99999642e-01]\n",
      " [4.92941976e-01 5.07058024e-01]\n",
      " [1.00000000e+00 1.11127347e-08]\n",
      " [2.17052420e-05 9.99978304e-01]\n",
      " [4.53442141e-07 9.99999523e-01]\n",
      " [1.00000000e+00 6.07306072e-09]\n",
      " [1.00000000e+00 4.23626867e-09]\n",
      " [9.66410880e-08 9.99999881e-01]\n",
      " [3.46866429e-01 6.53133512e-01]\n",
      " [4.07127878e-08 1.00000000e+00]\n",
      " [1.81634849e-08 1.00000000e+00]\n",
      " [5.02224054e-07 9.99999523e-01]\n",
      " [9.98787820e-01 1.21216988e-03]\n",
      " [9.96425092e-01 3.57494294e-03]\n",
      " [7.55070323e-06 9.99992490e-01]\n",
      " [9.84387327e-09 1.00000000e+00]\n",
      " [1.00000000e+00 1.19694796e-08]\n",
      " [1.00000000e+00 3.16558912e-09]\n",
      " [9.99999642e-01 3.41283993e-07]\n",
      " [6.91346447e-09 1.00000000e+00]\n",
      " [1.00000000e+00 8.42240055e-09]\n",
      " [9.99998331e-01 1.64541643e-06]\n",
      " [3.60052377e-06 9.99996424e-01]\n",
      " [9.39967752e-01 6.00322187e-02]\n",
      " [9.99999881e-01 9.59528705e-08]\n",
      " [1.00000000e+00 2.38915785e-08]\n",
      " [5.51005769e-07 9.99999404e-01]\n",
      " [9.99999881e-01 8.17020478e-08]\n",
      " [1.00000000e+00 3.67500093e-08]\n",
      " [1.06420801e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.62526028e-08]\n",
      " [8.30172360e-01 1.69827625e-01]\n",
      " [1.00000000e+00 2.44358613e-08]\n",
      " [9.99437630e-01 5.62325178e-04]\n",
      " [5.85879025e-06 9.99994159e-01]\n",
      " [1.00000000e+00 2.15011600e-08]\n",
      " [1.00000000e+00 4.75667372e-09]\n",
      " [9.87650692e-01 1.23493783e-02]\n",
      " [1.39369494e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.90682385e-08]\n",
      " [9.99802053e-01 1.97943795e-04]\n",
      " [7.03429635e-08 9.99999881e-01]\n",
      " [1.00000000e+00 6.15355056e-09]\n",
      " [1.00000000e+00 3.02222847e-09]\n",
      " [9.99999762e-01 2.95284622e-07]\n",
      " [1.59888968e-05 9.99984026e-01]\n",
      " [2.02157366e-08 1.00000000e+00]\n",
      " [3.17334440e-07 9.99999642e-01]\n",
      " [1.00000000e+00 3.13881188e-08]\n",
      " [9.99998927e-01 1.05208937e-06]\n",
      " [1.00000000e+00 3.92784649e-08]\n",
      " [1.00000000e+00 2.47020204e-09]\n",
      " [1.00000000e+00 3.29419159e-09]\n",
      " [3.07665164e-06 9.99996901e-01]\n",
      " [5.91518328e-05 9.99940872e-01]\n",
      " [9.99999881e-01 8.36687590e-08]\n",
      " [3.33161303e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.83224235e-08]\n",
      " [2.10039715e-07 9.99999762e-01]\n",
      " [1.21312119e-01 8.78687859e-01]\n",
      " [1.90989772e-06 9.99998093e-01]\n",
      " [1.31330697e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.28882442e-08]\n",
      " [9.99951720e-01 4.82263786e-05]\n",
      " [1.00000000e+00 2.84563857e-08]\n",
      " [2.09285901e-07 9.99999762e-01]\n",
      " [9.88223910e-01 1.17760114e-02]\n",
      " [2.71306000e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.62602917e-08]\n",
      " [1.00000000e+00 1.42800873e-08]\n",
      " [2.77160908e-08 1.00000000e+00]\n",
      " [1.00000000e+00 6.25387742e-09]\n",
      " [6.50805950e-01 3.49194080e-01]\n",
      " [9.95734036e-01 4.26594680e-03]\n",
      " [1.00885833e-08 1.00000000e+00]\n",
      " [1.31526939e-03 9.98684704e-01]\n",
      " [1.03004041e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.16395169e-08]\n",
      " [1.78786343e-06 9.99998212e-01]\n",
      " [1.00000000e+00 1.05160094e-08]\n",
      " [1.00000000e+00 4.80002837e-09]\n",
      " [1.00000000e+00 3.28108740e-08]\n",
      " [1.00000000e+00 1.04135953e-08]\n",
      " [1.00000000e+00 1.38902427e-08]\n",
      " [1.58844632e-04 9.99841094e-01]\n",
      " [4.45820160e-06 9.99995589e-01]\n",
      " [3.92101286e-03 9.96079028e-01]\n",
      " [9.99999881e-01 7.91019943e-08]\n",
      " [6.84090657e-03 9.93159115e-01]\n",
      " [9.99995112e-01 4.91471292e-06]\n",
      " [1.00000000e+00 1.57573101e-08]\n",
      " [1.23207293e-08 1.00000000e+00]\n",
      " [1.00000000e+00 6.54596155e-09]\n",
      " [1.71479098e-08 1.00000000e+00]\n",
      " [1.00000000e+00 3.14277742e-08]\n",
      " [7.63352455e-06 9.99992371e-01]\n",
      " [1.38149232e-06 9.99998569e-01]\n",
      " [4.10516705e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.72452949e-09]\n",
      " [7.68855443e-06 9.99992371e-01]\n",
      " [9.99937654e-01 6.22971347e-05]\n",
      " [1.05795544e-02 9.89420414e-01]\n",
      " [1.00000000e+00 1.16998367e-08]\n",
      " [1.97633024e-04 9.99802411e-01]\n",
      " [1.85373053e-02 9.81462717e-01]\n",
      " [4.87953752e-01 5.12046278e-01]\n",
      " [7.84950462e-05 9.99921441e-01]\n",
      " [1.00000000e+00 7.64779440e-09]\n",
      " [1.00000000e+00 2.06693791e-08]\n",
      " [1.55173111e-05 9.99984503e-01]\n",
      " [1.00000000e+00 7.02091629e-09]\n",
      " [9.99999881e-01 6.55886154e-08]\n",
      " [1.56136357e-05 9.99984384e-01]\n",
      " [9.99996185e-01 3.80161555e-06]\n",
      " [1.00000000e+00 1.47374335e-08]\n",
      " [8.78322423e-01 1.21677540e-01]\n",
      " [1.00000000e+00 2.75850720e-09]\n",
      " [4.56757135e-07 9.99999523e-01]\n",
      " [2.35459954e-08 1.00000000e+00]\n",
      " [9.99999881e-01 6.06160597e-08]\n",
      " [3.26683747e-08 1.00000000e+00]\n",
      " [9.99999881e-01 9.90835645e-08]\n",
      " [1.23721520e-07 9.99999881e-01]\n",
      " [1.05787556e-08 1.00000000e+00]\n",
      " [1.00000000e+00 4.64984540e-09]\n",
      " [2.52439141e-01 7.47560799e-01]\n",
      " [1.00000000e+00 2.14500400e-08]\n",
      " [1.00000000e+00 7.46114992e-09]\n",
      " [2.35962891e-03 9.97640371e-01]\n",
      " [1.00000000e+00 3.31524603e-08]\n",
      " [1.00000000e+00 1.24432749e-08]\n",
      " [1.00000000e+00 6.34729869e-09]\n",
      " [9.96817350e-01 3.18260305e-03]\n",
      " [1.48273155e-03 9.98517215e-01]\n",
      " [1.00000000e+00 1.50756456e-08]\n",
      " [1.60201736e-08 1.00000000e+00]\n",
      " [3.67781818e-02 9.63221788e-01]\n",
      " [9.99998212e-01 1.83368911e-06]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# test verilerinizi hazırlayın\n",
    "x_test = X_test\n",
    "\n",
    "# tahminleri yapın\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# tahmin sonuçlarını kontrol edin\n",
    "print(y_pred)  # (num_samples, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       261\n",
      "           1       0.81      0.74      0.78       239\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       500\n",
      "   macro avg       0.80      0.79      0.79       500\n",
      "weighted avg       0.80      0.79      0.79       500\n",
      " samples avg       0.79      0.79      0.79       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
